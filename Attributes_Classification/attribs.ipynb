{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import os\n",
    "from sys import exit\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import xml.etree.ElementTree as ET\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.data import Corpus\n",
    "\n",
    "tagger = SequenceTagger.load('ner')\n",
    "\n",
    "def lstSentences(data):\n",
    "    \"\"\"Gets data and splits text to tokens and puts them into a list\"\"\"\n",
    " \n",
    "    newfile = []\n",
    "    for subdir, dirs, files in os.walk('/Users/nihat/Downloads/spaceeval_trial_data'):\n",
    "        for filename in files:\n",
    "            filepath = subdir + os.sep + filename\n",
    "            if filepath.endswith(\".xml\"):\n",
    "                root = ET.parse(filepath)\n",
    "                t = root.find('TEXT')\n",
    "                text = t.text\n",
    "                doc = nlp(text)\n",
    "                for token in doc:\n",
    "                    newfile += [token.text]\n",
    "    return newfile\n",
    "\n",
    "\n",
    "trialLst = lstSentences('/Users/nihat/Downloads/spaceeval_trial_data') # dev = trial\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "k\n",
      "k\n",
      "H\n",
      "k\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n                        for subelem in elem.findall('PATH'):\\n                            newLst += [[subelem.get('text'),'PATH' ,subelem.get('dimensionality'),subelem.get('form')]]\\n                        for subelem in elem.findall('MOTION'):\\n                            newLst += [[subelem.get('text'), 'MOTION',subelem.get('motion_type'),subelem.get('motion_class'), ,subelem.get('motion_sense')]]\\n                        for subelem in elem.findall('NONMOTION_EVENT'):\\n                            newLst += [[subelem.get('text'), 'NONMOTION_EVENT']]\\n                        for subelem in elem.findall('SPATIAL_ENTITY'):\\n                            newLst += [[subelem.get('text'),'SPATIAL_ENTITY' ,subelem.get('form')]]\\n                        for subelem in elem.findall('SPATIAL_SIGNAL'):\\n                            newLst += [[subelem.get('text'),'SPATIAL_SIGNAL' ,subelem.get('semantic_type')]]\\n                        for subelem in elem.findall('MOTION_SIGNAL'):\\n                            newLst += [[subelem.get('text'),'MOTION_SIGNAL' ,subelem.get('motion_signal_type')]]\\n                        for subelem in elem.findall('MEASURE'):\\n                            newLst += [[subelem.get('text'),'MEASURE' ,subelem.get('value')]]\\n                        for subelem in elem.findall('PLACE'):\\n                            newLst += [[subelem.get('text'),'PLACE' ,subelem.get('dimensionality'),subelem.get('form')]]\\n                            \\n                            dim form motion_type motion_class motion_sense semantic_type motion_signal_type value\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setClass(file):\n",
    "    \"\"\"predicts if spatial entity/signal /place,...\"\"\"\n",
    "    # create string that will be converted to txt file later\n",
    "    print(\"H\")\n",
    "    newLst = []\n",
    "    for subdir, dirs, files in os.walk(file):\n",
    "        for filename in files:\n",
    "            filepath = subdir + os.sep + filename\n",
    "            print(\"k\")\n",
    "            if filepath.endswith(\".xml\"):\n",
    "                root = ET.parse(filepath)\n",
    "                print(\"l\")\n",
    "                t = root.find('TEXT')\n",
    "                text = t.text\n",
    "                doc = nlp(text)\n",
    "                tree = ET.parse(filepath)\n",
    "                root = tree.getroot()\n",
    "                doc = nlp(root[0].text)\n",
    "                for token in doc:\n",
    "                    found = False\n",
    "\n",
    "                    for elem in root:\n",
    "                        for subelem in elem: \n",
    "                            print(\"hi\")\n",
    "                            #PLACE, NONMOTION_EVENT, SPATIAL_ENTITY, MOTION, MOTION_SIGNAL, SPATIAL_SIGNAL, PATH, MEASURE,     \n",
    "                            if subelem.tag == \"PLACE\":\n",
    "                                if subelem.get('start') == str(token.idx):\n",
    "                                    newLst += [[subelem.get('text'),'PLACE' ,'dimensionality','form','', '', '', '', '','']]\n",
    "                                    found = True\n",
    "                            else: pass\n",
    "                            \n",
    "                            if not found:\n",
    "                                if subelem.tag == \"SPATIAL_SIGNAL\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        newLst += [[subelem.get('text'),'SPATIAL_SIGNAL' ,'','','', '', '', 'semantic_type', '', '']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"SPATIAL_ENTITY\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        newLst += [[subelem.get('text'),'SPATIAL_ENTITY' ,'','form','', '', '', '', '','']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"LOCATION\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        newLst += [[subelem.get('text') ,'LOCATION','','','', '', '', '', '','']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"MEASURE\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        newLst += [[subelem.get('text'),'MEASURE' ,'','','', '', '', '', '','value']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"MOTION\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        newLst += [[subelem.get('text'), 'MOTION', '', '','motion_type','motion_class', 'motion_sense', '','','']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"NONMOTION_EVENT\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        newLst += [[subelem.get('text') ,'NONMOTION_EVENT','','','', '', '', '', '','']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"MOTION_SIGNAL\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        newLst += [[subelem.get('text'),'MOTION_SIGNAL' ,'','','', '', '', '', 'motion_signal_type','']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"PATH\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        newLst += [[subelem.get('text'),'PATH' ,'dimensionality','form','', '', '', '', '','']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                    if not found: newLst += [[token.text ,' O','','','', '', '', '', '','']]\n",
    "        return newLst\n",
    "                        \n",
    "\n",
    " \n",
    "        \n",
    "trainSetClass = setClass('/Users/nihat/Downloads/Traning-2')\n",
    "testSetClass = setClass('/Users/nihat/Downloads/test_task8-2')\n",
    "print(\"\")\n",
    "\"\"\"\n",
    "                        for subelem in elem.findall('PATH'):\n",
    "                            newLst += [[subelem.get('text'),'PATH' ,subelem.get('dimensionality'),subelem.get('form')]]\n",
    "                        for subelem in elem.findall('MOTION'):\n",
    "                            newLst += [[subelem.get('text'), 'MOTION',subelem.get('motion_type'),subelem.get('motion_class'), ,subelem.get('motion_sense')]]\n",
    "                        for subelem in elem.findall('NONMOTION_EVENT'):\n",
    "                            newLst += [[subelem.get('text'), 'NONMOTION_EVENT']]\n",
    "                        for subelem in elem.findall('SPATIAL_ENTITY'):\n",
    "                            newLst += [[subelem.get('text'),'SPATIAL_ENTITY' ,subelem.get('form')]]\n",
    "                        for subelem in elem.findall('SPATIAL_SIGNAL'):\n",
    "                            newLst += [[subelem.get('text'),'SPATIAL_SIGNAL' ,subelem.get('semantic_type')]]\n",
    "                        for subelem in elem.findall('MOTION_SIGNAL'):\n",
    "                            newLst += [[subelem.get('text'),'MOTION_SIGNAL' ,subelem.get('motion_signal_type')]]\n",
    "                        for subelem in elem.findall('MEASURE'):\n",
    "                            newLst += [[subelem.get('text'),'MEASURE' ,subelem.get('value')]]\n",
    "                        for subelem in elem.findall('PLACE'):\n",
    "                            newLst += [[subelem.get('text'),'PLACE' ,subelem.get('dimensionality'),subelem.get('form')]]\n",
    "                            \n",
    "                            dim form motion_type motion_class motion_sense semantic_type motion_signal_type value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29323\n",
      "22500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(trainSetClass))\n",
    "print(len(testSetClass))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# erst listen bearbeiten \n",
    "# 1.erst keine empty lines\n",
    "# 2.remove lines with no text\n",
    "# 3.remove lines with no text but with entity\n",
    "\n",
    "# 4.add empty lines at the end of a sentence\n",
    "def updateList(lst):\n",
    "    # 1.erst keine empty lines\n",
    "    newLst = []\n",
    "    for each in range(0,len(lst)):\n",
    "        # 2und3.erst keine no texts\n",
    "        if lst[each][0]!= \"        \" or lst[each][0]!= \" \" :\n",
    "            #lst.remove('rabbit')\n",
    "            newLst += [lst[each]]\n",
    "        if lst[each][0]== \".\" or lst[each][0]== \"!\" or lst[each][0]== \"?\":\n",
    "            newLst += [[\"\",\"\"]]\n",
    "            \n",
    "    return newLst\n",
    "#testSetClass = updateList(testSetClass)\n",
    "#trainSetClass = updateList(trainSetClass)\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('/Users/nihat/Desktop/test10.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['text', 'iso','dimensionality','form', 'motion_type', 'motion_class', 'motion_sense', 'semantic_type', 'motion_signal_type', 'value']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for each in range(0,len(testSetClass)):\n",
    "        if testSetClass[each][0] != \"        \":\n",
    "            writer.writerow({'text': testSetClass[each][0], 'iso': testSetClass[each][1]})\n",
    "        \n",
    "        \n",
    "with open('/Users/nihat/Desktop/train10.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['text', 'iso','dimensionality','form', 'motion_type', 'motion_class', 'motion_sense', 'semantic_type', 'motion_signal_type', 'value']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for each in range(0,len(trainSetClass)):\n",
    "        if trainSetClass[each][0] != \"        \":\n",
    "            writer.writerow({'text': trainSetClass[each][0], 'iso': trainSetClass[each][1]})\n",
    "            #print(\"''\"+trainSetClass[each][0]+\"''\")\n",
    "            #break\n",
    "\n",
    "        \n",
    "        \n",
    "with open('/Users/nihat/Desktop/trial10.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['text','iso']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for each in range(0,len(trialLst)):\n",
    "        writer.writerow({'text': trialLst[each]})\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setClass(file):\n",
    "    \"\"\"predicts if spatial entity/signal /place,...\"\"\"\n",
    "    # create string that will be converted to txt file later\n",
    "    newfile = []\n",
    "    for subdir, dirs, files in os.walk(file):\n",
    "        for filename in files:\n",
    "            filepath = subdir + os.sep + filename\n",
    "            if filepath.endswith(\".xml\"):\n",
    "                root = ET.parse(filepath)\n",
    "\n",
    "                t = root.find('TEXT')\n",
    "                text = t.text\n",
    "                doc = nlp(text)\n",
    "                tree = ET.parse(filepath)\n",
    "                root = tree.getroot()\n",
    "                doc = nlp(root[0].text)\n",
    "                #for sent in doc.sents:\n",
    "                #    sen = Sentence(sent.text)\n",
    "                #    sentences.append(sen)\n",
    "                for token in doc:\n",
    "                    found = False\n",
    "\n",
    "                    for elem in root:\n",
    "                        for subelem in elem: \n",
    "                            if subelem.tag == \"PLACE\":\n",
    "                                if subelem.get('start') == str(token.idx):\n",
    "                                    txt = subelem.get('text')\n",
    "                                    x = txt.split(\" \")\n",
    "                                    for e in range(0,len(x)):\n",
    "                                       \n",
    "                                        newfile += [[x[e] ,' PLACE', ' dimensionality',' form' ,'  ', '  ', '  ', '  ', '  ','  ']]\n",
    "                                    found = True\n",
    "                            else: pass\n",
    "                            \n",
    "                            if not found:\n",
    "                                if subelem.tag == \"SPATIAL_SIGNAL\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        txt = subelem.get('text')\n",
    "                                        x = txt.split(\" \")\n",
    "                                        for e in range(0,len(x)):\n",
    "                                            newfile += [[x[e] ,' SPATIAL_SIGNAL', '  ','  ' ,'  ', '  ', '  ', ' semantic_type', '  ','  ']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"SPATIAL_ENTITY\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        txt = subelem.get('text')\n",
    "                                        x = txt.split(\" \")\n",
    "                                        for e in range(0,len(x)):\n",
    "                                            newfile += [[x[e] ,' SPATIAL_ENTITY', '  ',' form' +'  ', '  ', '  ', '  ', '  ','  ']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"LOCATION\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        txt = subelem.get('text')\n",
    "                                        x = txt.split(\" \")\n",
    "                                        for e in range(0,len(x)):\n",
    "                                            newfile += [[x[e] ,' LOCATION', '  ','  ' ,'  ', '  ', '  ', '  ', '  ','  ']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"MEASURE\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        txt = subelem.get('text')\n",
    "                                        x = txt.split(\" \")\n",
    "                                        for e in range(0,len(x)):\n",
    "                                            newfile += [[x[e] ,' MEASURE', '  ','  ' ,'  ', '  ', '  ', '  ', '  ',' value']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"MOTION\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        txt = subelem.get('text')\n",
    "                                        x = txt.split(\" \")\n",
    "                                        for e in range(0,len(x)):\n",
    "                                            newfile += [[x[e] ,' MOTION', '  ', '  ',' motion_type',' motion_class', ' motion_sense', '  ','  ','  ']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"NONMOTION_EVENT\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        txt = subelem.get('text')\n",
    "                                        x = txt.split(\" \")\n",
    "                                        for e in range(0,len(x)):\n",
    "                                            newfile += [[x[e] ,' NONMOTION_EVENT', '  ','  ' ,'  ', '  ', '  ', '  ', '  ','  ']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"MOTION_SIGNAL\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        txt = subelem.get('text')\n",
    "                                        x = txt.split(\" \")\n",
    "                                        for e in range(0,len(x)):\n",
    "                                            newfile += [[x[e] ,' MOTION_SIGNAL' , '  ','  ' ,'  ', '  ', '  ', '  ', ' motion_signal_type','  ']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                            if not found:\n",
    "                                if subelem.tag == \"PATH\":\n",
    "                                    if subelem.get('start') == str(token.idx):\n",
    "                                        txt = subelem.get('text')\n",
    "                                        x = txt.split(\" \")\n",
    "                                        for e in range(0,len(x)):\n",
    "                                            newfile += [[x[e] ,' PATH', ' dimensionality',' form' ,'  ', '  ', '  ', '  ', '  ','  ']]\n",
    "                                        found = True\n",
    "                            else: pass\n",
    "\n",
    "                    if not found: newfile += [[token.text ,' O', '  ','  ' ,'  ','  ', '  ', '  ', '  ','  ']]\n",
    "                #print(newfile)\n",
    "    return newfile\n",
    "\n",
    "trainSetClass = setClass('/Users/nihat/Downloads/Traning-2')\n",
    "testSetClass = setClass('/Users/nihat/Downloads/test_task8-2')\n",
    "print(\"\")\n",
    "print(len(trainSetClass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n",
      "29323\n",
      "10\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f6a4ebb3da0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m                             \u001b[0;34m'motion_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainSetClass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'motion_class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainSetClass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                             \u001b[0;34m'motion_sense'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainSetClass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'semantic_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainSetClass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                             'motion_signal_type': trainSetClass[each][8], 'value': trainSetClass[each][9]})\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(len(testSetClass))\n",
    "print(len(trainSetClass))\n",
    "print(len(['' ,' NONMOTION_EVENT', '  ','  ' ,'  ', '  ', '  ', '  ', '  ','  ']))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# erst listen bearbeiten \n",
    "# 1.erst keine empty lines\n",
    "# 2.remove lines with no text\n",
    "# 3.remove lines with no text but with entity\n",
    "\n",
    "# 4.add empty lines at the end of a sentence\n",
    "def updateList(lst):\n",
    "    # 1.erst keine empty lines\n",
    "    newLst = []\n",
    "    for each in range(0,len(lst)):\n",
    "        # 2und3.erst keine no texts\n",
    "        if lst[each][0]!= \"        \" or lst[each][0]!= \" \" :\n",
    "            #lst.remove('rabbit')\n",
    "            newLst += [lst[each]]\n",
    "        if lst[each][0]== \".\" or lst[each][0]== \"!\" or lst[each][0]== \"?\":\n",
    "            newLst += [[\"\",\"\"]]\n",
    "            \n",
    "    return newLst\n",
    "#testSetClass = updateList(testSetClass)\n",
    "#trainSetClass = updateList(trainSetClass)\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('/Users/nihat/Desktop/test10.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['text', 'iso','dimensionality','form', 'motion_type', 'motion_class', 'motion_sense', 'semantic_type', 'motion_signal_type', 'value']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for each in range(0,len(testSetClass)):\n",
    "        if testSetClass[each][0] != \"        \":\n",
    "            writer.writerow({'text': testSetClass[each][0], 'iso': testSetClass[each][1],\n",
    "                            'dimensionality': trainSetClass[each][2], 'form': trainSetClass[each][3],\n",
    "                            'motion_type': trainSetClass[each][4], 'motion_class': trainSetClass[each][5],\n",
    "                            'motion_sense': trainSetClass[each][6], 'semantic_type': trainSetClass[each][7],\n",
    "                            'motion_signal_type': trainSetClass[each][8], 'value': trainSetClass[each][9]})\n",
    "        \n",
    "        \n",
    "with open('/Users/nihat/Desktop/train10.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['text', 'iso','dimensionality','form', 'motion_type', 'motion_class', 'motion_sense', 'semantic_type', 'motion_signal_type', 'value']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for each in range(0,len(trainSetClass)):\n",
    "        if trainSetClass[each][0] != \"        \":\n",
    "            writer.writerow({'text': trainSetClass[each][0], 'iso': trainSetClass[each][1],\n",
    "                            'dimensionality': trainSetClass[each][2], 'form': trainSetClass[each][3],\n",
    "                            'motion_type': trainSetClass[each][4], 'motion_class': trainSetClass[each][5],\n",
    "                            'motion_sense': trainSetClass[each][6], 'semantic_type': trainSetClass[each][7],\n",
    "                            'motion_signal_type': trainSetClass[each][8], 'value': trainSetClass[each][9]})\n",
    "            #print(\"''\"+trainSetClass[each][0]+\"''\")\n",
    "            #break\n",
    "\n",
    "        \n",
    "        \n",
    "with open('/Users/nihat/Desktop/trial10.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['text','iso']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for each in range(0,len(trialLst)):\n",
    "        writer.writerow({'text': trialLst[each]})\n",
    "\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
