{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-06 14:28:02,210 Reading data from corpus\n",
      "2021-02-06 14:28:02,214 Train: corpus\\train.txt\n",
      "2021-02-06 14:28:02,215 Dev: None\n",
      "2021-02-06 14:28:02,215 Test: corpus\\test.txt\n",
      "Corpus: 1003 train + 112 dev + 289 test sentences\n",
      "[b'<unk>', b'O', b'PLACE', b'SPATIAL_ENTITY', b'NONMOTION_EVENT', b'SPATIAL_SIGNAL', b'MOTION', b'MOTION_SIGNAL', b'PATH', b'MEASURE', b'<START>', b'<STOP>']\n",
      "2021-02-06 14:28:12,752 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:28:12,764 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): TransformerWordEmbeddings(\n",
      "      (model): DistilBertModel(\n",
      "        (embeddings): Embeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (transformer): Transformer(\n",
      "          (layer): ModuleList(\n",
      "            (0): TransformerBlock(\n",
      "              (attention): MultiHeadSelfAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "            (1): TransformerBlock(\n",
      "              (attention): MultiHeadSelfAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "            (2): TransformerBlock(\n",
      "              (attention): MultiHeadSelfAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "            (3): TransformerBlock(\n",
      "              (attention): MultiHeadSelfAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "            (4): TransformerBlock(\n",
      "              (attention): MultiHeadSelfAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "            (5): TransformerBlock(\n",
      "              (attention): MultiHeadSelfAttention(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              )\n",
      "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (ffn): FFN(\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              )\n",
      "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)\n",
      "  (rnn): LSTM(3072, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-02-06 14:28:12,767 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:28:12,769 Corpus: \"Corpus: 1003 train + 112 dev + 289 test sentences\"\n",
      "2021-02-06 14:28:12,771 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:28:12,773 Parameters:\n",
      "2021-02-06 14:28:12,776  - learning_rate: \"0.5\"\n",
      "2021-02-06 14:28:12,779  - mini_batch_size: \"32\"\n",
      "2021-02-06 14:28:12,781  - patience: \"3\"\n",
      "2021-02-06 14:28:12,784  - anneal_factor: \"0.5\"\n",
      "2021-02-06 14:28:12,786  - max_epochs: \"3\"\n",
      "2021-02-06 14:28:12,788  - shuffle: \"True\"\n",
      "2021-02-06 14:28:12,791  - train_with_dev: \"False\"\n",
      "2021-02-06 14:28:12,793  - batch_growth_annealing: \"False\"\n",
      "2021-02-06 14:28:12,795 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:28:12,796 Model training base path: \"resources2\\taggers\\example-iso\"\n",
      "2021-02-06 14:28:12,799 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:28:12,804 Device: cpu\n",
      "2021-02-06 14:28:12,806 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:28:12,807 Embeddings storage mode: cpu\n",
      "2021-02-06 14:28:12,822 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:29:32,696 epoch 1 - iter 3/32 - loss 49.41168976 - samples/sec: 1.21 - lr: 0.500000\n",
      "2021-02-06 14:30:20,384 epoch 1 - iter 6/32 - loss 56.95916112 - samples/sec: 2.02 - lr: 0.500000\n",
      "2021-02-06 14:31:06,135 epoch 1 - iter 9/32 - loss 56.38398573 - samples/sec: 2.10 - lr: 0.500000\n",
      "2021-02-06 14:31:52,990 epoch 1 - iter 12/32 - loss 53.89106719 - samples/sec: 2.05 - lr: 0.500000\n",
      "2021-02-06 14:32:42,610 epoch 1 - iter 15/32 - loss 54.91752040 - samples/sec: 1.94 - lr: 0.500000\n",
      "2021-02-06 14:33:00,166 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:33:00,169 Exiting from training early.\n",
      "2021-02-06 14:33:00,172 Saving model ...\n",
      "2021-02-06 14:33:05,348 Done.\n",
      "2021-02-06 14:33:05,351 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-06 14:33:05,352 Testing using best model ...\n",
      "2021-02-06 14:33:29,606 \t0.0549\n",
      "2021-02-06 14:33:29,607 \n",
      "Results:\n",
      "- F-score (micro): 0.0549\n",
      "- F-score (macro): 0.0226\n",
      "- Accuracy (incl. no class): 0.0549\n",
      "\n",
      "By class:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "              O     1.0000    0.0000    0.0000      5710\n",
      " SPATIAL_ENTITY     0.0415    0.3967    0.0751       363\n",
      "          PLACE     0.0722    0.5813    0.1284       449\n",
      "NONMOTION_EVENT     1.0000    0.0000    0.0000        69\n",
      "        MEASURE     1.0000    0.0000    0.0000        73\n",
      " SPATIAL_SIGNAL     1.0000    0.0000    0.0000       188\n",
      "           PATH     1.0000    0.0000    0.0000       158\n",
      "  MOTION_SIGNAL     0.0000    0.0000    0.0000       164\n",
      "         MOTION     1.0000    0.0000    0.0000       202\n",
      "\n",
      "       accuracy                         0.0549      7376\n",
      "      macro avg     0.6793    0.1087    0.0226      7376\n",
      "   weighted avg     0.8741    0.0549    0.0115      7376\n",
      "\n",
      "2021-02-06 14:33:29,608 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.0549,\n",
       " 'dev_score_history': [],\n",
       " 'train_loss_history': [],\n",
       " 'dev_loss_history': []}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "from flair.data import Corpus\n",
    "from typing import List\n",
    "from flair.embeddings import (\n",
    "    TokenEmbeddings,\n",
    "    WordEmbeddings,\n",
    "    StackedEmbeddings,\n",
    "    FlairEmbeddings,\n",
    "    TransformerWordEmbeddings,\n",
    "    CharacterEmbeddings,)\n",
    "from flair.training_utils import EvaluationMetric\n",
    "from flair.visual.training_curves import Plotter\n",
    "# from flair.datasets import ClassificationCorpus doesnt work with this\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = './corpus'\n",
    "\n",
    "# define columns\n",
    "columns = {0: 'text', 1: 'iso'}\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                                      test_file='test.txt', \n",
    "                                      train_file='train.txt')\n",
    "print(corpus)\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = \"iso\"\n",
    "\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)\n",
    "\n",
    "# initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    #WordEmbeddings(\"glove\"),\n",
    "    TransformerWordEmbeddings('distilbert-base-uncased', fine_tune=True),\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "    # comment in these lines to use contextual string embeddings\n",
    "    #\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    #\n",
    "    # FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(\n",
    "    hidden_size=256,\n",
    "    embeddings=embeddings,\n",
    "    tag_dictionary=tag_dictionary,\n",
    "    tag_type=tag_type,\n",
    "    use_crf=True,\n",
    ")\n",
    "\n",
    "# initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "trainer.train(\n",
    "    \"resources2/taggers/example-iso\",\n",
    "    learning_rate=0.5,\n",
    "    mini_batch_size=32,\n",
    "    max_epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
